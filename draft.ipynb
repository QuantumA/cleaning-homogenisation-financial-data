{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from time import mktime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "import re\n",
    "import io\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_indices = [\"%5EIBEX\", \"%5EBFX\",\"%5EBVSP\", \"%5EDJI\", \"%5EFCHI\", \"%5EFTSE\", \"%5EGDAXI\", \"%5EHSI\", \n",
    "                \"%5EMXX\", \"%5EJKSE\", \"%5EMERV\", \"%5EOMXSPI\", \"%5EOSEAX\", \"%5ESSMI\", \"%5ESTI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix(date):\n",
    "    \"\"\"\n",
    "    converts date to unix timestamp\n",
    "    \n",
    "    parameters: date - in format (dd-mm-yyyy)\n",
    "    \n",
    "    returns integer unix timestamp\n",
    "    \"\"\"\n",
    "    datum = dt.datetime.strptime(date, '%d-%m-%Y')\n",
    "    \n",
    "    return int(mktime(datum.timetuple()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crumbs_and_cookies(ticker: str):\n",
    "    # Thanks to MAIK ROSENHEINRICH\n",
    "    \"\"\"\n",
    "    get crumb and cookies for historical data csv download from yahoo finance  \n",
    "    parameters: stock - short-handle identifier of the company    \n",
    "    returns a tuple of header, crumb and cookie\n",
    "    \"\"\"   \n",
    "    url = 'https://finance.yahoo.com/quote/{}/history'.format(ticker)\n",
    "    \n",
    "    with requests.session():\n",
    "        header = {'Connection': 'keep-alive',\n",
    "                   'Expires': '-1',\n",
    "                   'Upgrade-Insecure-Requests': '1',\n",
    "                   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) \\\n",
    "                   AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'\n",
    "                   }        \n",
    "        website = requests.get(url, headers=header)\n",
    "        soup = BeautifulSoup(website.text, 'lxml')\n",
    "        \n",
    "        crumb = re.findall('\"CrumbStore\":{\"crumb\":\"(.+?)\"}', str(soup))\n",
    "        output=(header, crumb[0], website.cookies)\n",
    "        return output   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_begin_unix = convert_to_unix(\"01-12-2018\")\n",
    "day_end_unix = convert_to_unix(\"21-09-2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, crumb, cookies = get_crumbs_and_cookies(lista_indices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.session():\n",
    "        \n",
    "            url = 'https://query1.finance.yahoo.com/v7/finance/download/' \\\n",
    "                '{stock}?period1={day_begin}&period2={day_end}&interval={interval}&events=history&crumb={crumb}' \\\n",
    "                .format(stock=lista_indices[1], day_begin=day_begin_unix, day_end=day_end_unix, interval='1d', crumb=crumb)\n",
    "                \n",
    "            website = requests.get(url, headers=header, cookies=cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(tickers: List[str], day_begin: str, day_end: str, interval='1d'):\n",
    "\n",
    "    historical_prices = None\n",
    "    df_create = False\n",
    "\n",
    "\n",
    "    for ticker in tickers:\n",
    "        error1='404 Not Found: Timestamp data missing.' \n",
    "    \n",
    "        day_begin_unix = convert_to_unix(day_begin)\n",
    "        day_end_unix = convert_to_unix(day_end)   \n",
    "    \n",
    "        header, crumb, cookies = get_crumbs_and_cookies(ticker)\n",
    "    \n",
    "        with requests.session():\n",
    "        \n",
    "            url = 'https://query1.finance.yahoo.com/v7/finance/download/' \\\n",
    "                '{stock}?period1={day_begin}&period2={day_end}&interval={interval}&events=history&crumb={crumb}' \\\n",
    "                .format(stock=ticker, day_begin=day_begin_unix, day_end=day_end_unix, interval=interval, crumb=crumb)\n",
    "\n",
    "            print(url)\n",
    "                \n",
    "            website = requests.get(url, headers=header, cookies=cookies)\n",
    "            if website.status_code == 200:\n",
    "                if not df_create:\n",
    "                    historical_prices = pd.read_csv(io.StringIO(website.text))\n",
    "                    historical_prices[\"ticker\"] = ticker\n",
    "                    df_create = True\n",
    "                else:\n",
    "                    temp_df = pd.read_csv(io.StringIO(website.text))\n",
    "                    temp_df[\"ticker\"] = ticker\n",
    "                    historical_prices = historical_prices.append(temp_df, ignore_index=True)\n",
    "                \n",
    "                print(\"Obteniendo histórico para {}\".format(ticker))\n",
    "                print(\"longitud del df: {}\".format(len(historical_prices.Date)))\n",
    "            \n",
    "            else:\n",
    "                print(\"Error downloading data from ticker {}\".format(ticker))\n",
    "                print(\"Response was {}\".format(website.text))\n",
    "\n",
    "\n",
    "    historical_prices.drop_duplicates()\n",
    "    historical_prices.Date = historical_prices.Date.astype(np.datetime64)\n",
    "    #historical_prices = historical_prices.dropna()\n",
    "    return historical_prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency(tickers: List[str]):\n",
    "    \n",
    "    indice_divisa = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "\n",
    "        header, crumb, cookies = get_crumbs_and_cookies(ticker)\n",
    "            \n",
    "        with requests.session():\n",
    "                \n",
    "            url = \"https://es.finance.yahoo.com/quote/\"+ticker+\"/components/\"            \n",
    "            website = requests.get(url, headers=header, cookies=cookies)\n",
    "\n",
    "        soup = BeautifulSoup(website.text)\n",
    "        divisa = re.findall('Divisa en [a-zA-Z]{3}', str(soup))\n",
    "        divisa = divisa[0][len(divisa[0])-3:]\n",
    "        indice_divisa.append((ticker, divisa))\n",
    "\n",
    "    return indice_divisa\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(tickers=List[str]):\n",
    "\n",
    "    componentes = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "\n",
    "        header, crumb, cookies = get_crumbs_and_cookies(ticker)\n",
    "                    \n",
    "        with requests.session():\n",
    "                        \n",
    "            intentos = 3\n",
    "            while intentos > 0:\n",
    "                url = \"https://es.finance.yahoo.com/quote/\"+ticker+\"/components/\"            \n",
    "                website = requests.get(url, headers=header, cookies=cookies)\n",
    "\n",
    "                print(\"Obteniendo componentes de {}\".format(ticker))\n",
    "                if website.status_code == 200:\n",
    "\n",
    "                    soup = BeautifulSoup(website.text)\n",
    "                    try:\n",
    "                        df = pd.read_html(str(soup))[0]\n",
    "                        df = df.iloc[:,[0,1]]\n",
    "                        componentes[ticker] = df.to_dict()\n",
    "\n",
    "                    except ValueError as ve:\n",
    "                        print(ve)\n",
    "                        print(url)\n",
    "                        next\n",
    "                    intentos = 0\n",
    "                else:\n",
    "                    print(\"Error al conectar con yahoo, intentos restantes: {}\".format(intentos))\n",
    "                    intentos -= 1\n",
    "                    if intentos == 0:\n",
    "                        print(\"No se ha conseguido descargar información para el ticker: {}\".format(ticker))\n",
    "\n",
    "\n",
    "        \n",
    "    return componentes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_days(lista_indices: List[str], historical_prices: pd.DataFrame):\n",
    "    market_days = {}\n",
    "    for idx in lista_indices:\n",
    "        market_days[idx] = list(historical_prices[historical_prices[\"ticker\"] == idx].Date)\n",
    "\n",
    "    return market_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_days(begin_date: str, end_date: str):\n",
    "\n",
    "    b = dt.datetime.strptime(begin_date, \"%d-%m-%Y\")\n",
    "    e = dt.datetime.strptime(end_date, \"%d-%m-%Y\")\n",
    "\n",
    "    bdays = pd.date_range(start=b, end=e, freq='B')\n",
    "    bdays = bdays.to_frame(index=False)\n",
    "    bdays.columns = ['Date']\n",
    "\n",
    "    return bdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogenize(price_data: pd.DataFrame, dates: pd.DataFrame):\n",
    "\n",
    "    indices = np.unique(price_data[\"ticker\"])\n",
    "    homogenized_prices = []\n",
    "\n",
    "    for idx in indices:\n",
    "        tmp_df = pd.merge(price_data[price_data.ticker == idx], dates, how=\"outer\", on=\"Date\")\n",
    "\n",
    "        tmp_df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "        \n",
    "        # Sustituir NA por el valor de la fila anterior. Si la fila con NA es la 1ª deja el NA sin dar un error.\n",
    "        print(tmp_df.isna().any())\n",
    "        tmp_df.fillna(method='ffill', inplace=True)\n",
    "        print(tmp_df.isna().any())\n",
    "        # Si los NA están en las primeras filas no \n",
    "        # hemos solucionado el problema. En principio no debería de haber más que dos (sábado y domingo), \n",
    "        # pero una empresa podría no cotizar lunes, martes... por lo que no conocemos el nº de potenciales NA a resolver.\n",
    "        # Para resolver el problema, invertimos el orden del DF, aplicamos na.locf de nuevo y devolvemos el DF a su posición original.\n",
    "        tmp_df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "        tmp_df.fillna(method='ffill', inplace=True)\n",
    "        print(tmp_df.isna().any())\n",
    "        tmp_df.sort_values(by='Date', ascending=False, inplace=True)\n",
    "        break \n",
    "    \n",
    "        homogenized_prices.append(tmp_df)\n",
    "\n",
    "    \n",
    "    return homogenized_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date         Open         High          Low        Close    Adj Close  \\\n",
      "0 2018-01-02  3990.370117  3991.899902  3957.760010  3979.530029  3979.530029   \n",
      "1 2018-01-03  3988.100098  4012.330078  3974.209961  4005.610107  4005.610107   \n",
      "2 2018-01-04  4025.780029  4065.600098  4023.330078  4057.919922  4057.919922   \n",
      "3 2018-01-05  4067.739990  4097.939941  4067.699951  4097.040039  4097.040039   \n",
      "4 2018-01-08  4114.399902  4124.459961  4110.500000  4114.529785  4114.529785   \n",
      "\n",
      "       Volume  ticker  \n",
      "0  21160100.0  %5EBFX  \n",
      "1  25869300.0  %5EBFX  \n",
      "2  32912700.0  %5EBFX  \n",
      "3  25470800.0  %5EBFX  \n",
      "4  21194600.0  %5EBFX  \n",
      "          Date         Open         High          Low        Close  \\\n",
      "510 2018-01-01          NaN          NaN          NaN          NaN   \n",
      "0   2018-01-02  3990.370117  3991.899902  3957.760010  3979.530029   \n",
      "1   2018-01-03  3988.100098  4012.330078  3974.209961  4005.610107   \n",
      "2   2018-01-04  4025.780029  4065.600098  4023.330078  4057.919922   \n",
      "3   2018-01-05  4067.739990  4097.939941  4067.699951  4097.040039   \n",
      "\n",
      "       Adj Close      Volume  ticker  \n",
      "510          NaN         NaN     NaN  \n",
      "0    3979.530029  21160100.0  %5EBFX  \n",
      "1    4005.610107  25869300.0  %5EBFX  \n",
      "2    4057.919922  32912700.0  %5EBFX  \n",
      "3    4097.040039  25470800.0  %5EBFX  \n",
      "          Date         Open         High          Low        Close  \\\n",
      "510 2018-01-01          NaN          NaN          NaN          NaN   \n",
      "0   2018-01-02  3990.370117  3991.899902  3957.760010  3979.530029   \n",
      "1   2018-01-03  3988.100098  4012.330078  3974.209961  4005.610107   \n",
      "2   2018-01-04  4025.780029  4065.600098  4023.330078  4057.919922   \n",
      "3   2018-01-05  4067.739990  4097.939941  4067.699951  4097.040039   \n",
      "\n",
      "       Adj Close      Volume  ticker  \n",
      "510          NaN         NaN     NaN  \n",
      "0    3979.530029  21160100.0  %5EBFX  \n",
      "1    4005.610107  25869300.0  %5EBFX  \n",
      "2    4057.919922  32912700.0  %5EBFX  \n",
      "3    4097.040039  25470800.0  %5EBFX  \n"
     ]
    }
   ],
   "source": [
    "x = homogenize(df, dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = get_business_days(\"01-01-2018\", \"01-01-2019\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[df.ticker == np.unique(df[\"ticker\"])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://query1.finance.yahoo.com/v7/finance/download/%5EIBEX?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=wP2sZn2Cviu\n",
      "Obteniendo histórico para %5EIBEX\n",
      "longitud del df: 511\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EBFX?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=vbV42MqwWF\\u002F\n",
      "Obteniendo histórico para %5EBFX\n",
      "longitud del df: 1021\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EBVSP?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=4Sg5z7OCJ.N\n",
      "Obteniendo histórico para %5EBVSP\n",
      "longitud del df: 1515\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EDJI?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=RSvNnLubdwK\n",
      "Obteniendo histórico para %5EDJI\n",
      "longitud del df: 2018\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EFCHI?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=nmcjPaZR.7X\n",
      "Obteniendo histórico para %5EFCHI\n",
      "longitud del df: 2529\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EFTSE?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=\\u002FtV9ahoE5zM\n",
      "Obteniendo histórico para %5EFTSE\n",
      "longitud del df: 3035\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EGDAXI?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=yrjSqgDxTId\n",
      "Obteniendo histórico para %5EGDAXI\n",
      "longitud del df: 3538\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EHSI?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=yaa4Yx407Ep\n",
      "Obteniendo histórico para %5EHSI\n",
      "longitud del df: 4030\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EMXX?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=NG90ofliE16\n",
      "Obteniendo histórico para %5EMXX\n",
      "longitud del df: 4532\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EJKSE?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=dRw0U553JKl\n",
      "Obteniendo histórico para %5EJKSE\n",
      "longitud del df: 5050\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EMERV?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=7842zugCDV9\n",
      "Obteniendo histórico para %5EMERV\n",
      "longitud del df: 5538\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EOMXSPI?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=mh0I3QDILQg\n",
      "Obteniendo histórico para %5EOMXSPI\n",
      "longitud del df: 6037\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5EOSEAX?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=zbjUqI.W2Xy\n",
      "Obteniendo histórico para %5EOSEAX\n",
      "longitud del df: 6535\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5ESSMI?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=EMS.AZ7LXz7\n",
      "Obteniendo histórico para %5ESSMI\n",
      "longitud del df: 7033\n",
      "https://query1.finance.yahoo.com/v7/finance/download/%5ESTI?period1=1514761200&period2=1577833200&interval=1d&events=history&crumb=rq88ZIVPQ2m\n",
      "Obteniendo histórico para %5ESTI\n",
      "longitud del df: 7537\n",
      "Obteniendo componentes de %5EIBEX\n",
      "Obteniendo componentes de %5EBFX\n",
      "Obteniendo componentes de %5EBVSP\n",
      "Obteniendo componentes de %5EDJI\n",
      "No tables found\n",
      "https://es.finance.yahoo.com/quote/%5EDJI/components/\n",
      "Obteniendo componentes de %5EFCHI\n",
      "Obteniendo componentes de %5EFTSE\n",
      "Obteniendo componentes de %5EGDAXI\n",
      "Obteniendo componentes de %5EHSI\n",
      "Obteniendo componentes de %5EMXX\n",
      "Obteniendo componentes de %5EJKSE\n",
      "Obteniendo componentes de %5EMERV\n",
      "Obteniendo componentes de %5EOMXSPI\n",
      "Obteniendo componentes de %5EOSEAX\n",
      "Obteniendo componentes de %5ESSMI\n",
      "Obteniendo componentes de %5ESTI\n"
     ]
    }
   ],
   "source": [
    "# Descargamos los indices de la lista\n",
    "df = get_historical_data(lista_indices, \"01-01-2018\", \"01-01-2020\", interval='1d')\n",
    "# Para cada indice listamos los componentes que cotizan en el indice\n",
    "componentes = get_components(lista_indices)\n",
    "# Nos quedamos solo con los indices de los que tenemos componentes\n",
    "indices = list(set(componentes.keys()) & set(np.unique(df[\"ticker\"])))\n",
    "df = df[df.ticker.isin(indices)]\n",
    "# Extraemos los días con los que queremos trabajar ( puede haber días que el índice no cotizó pero queremos tener los precios de ese día)\n",
    "market_days = get_business_days(\"01-01-2018\", \"01-01-2020\")\n",
    "# Homogeneizamos los datos de los indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b93c986a772c3d915d9a0c0155b758281b32f4512146cda581c6cbe9e806c15"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
